{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cccd07c8",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae69454",
   "metadata": {},
   "source": [
    "## Presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc15447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from matplotlib_map_utils import north_arrow\n",
    "\n",
    "from pyproj import Transformer\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "# =============================================================================\n",
    "# 1. DEFINIÇÃO DOS PARÂMETROS\n",
    "# =============================================================================\n",
    "\n",
    "# Input raster maps:\n",
    "# path_series_x = r\"C:\\Users\\AntFonseca\\github\\compare-time-series\\input\\collection6\"\n",
    "# path_series_y = r\"C:\\Users\\AntFonseca\\github\\compare-time-series\\input\\collection8\"\n",
    "# time_points = [1990, 1995, 2000, 2005, 2010, 2015, 2020]\n",
    "# class_name = \"soybean\"\n",
    "path_series_x = r\"C:\\Users\\AntFonseca\\github\\compare-time-series\\input\\toydata\\x\"\n",
    "path_series_y = r\"C:\\Users\\AntFonseca\\github\\compare-time-series\\input\\toydata\\y\"\n",
    "time_points = [0, 1, 2]\n",
    "class_name = \"toydata\"\n",
    "\n",
    "# Valor que representa 'NoData' nos arquivos raster\n",
    "nodata_value = 255\n",
    "\n",
    "# =============================================================================\n",
    "# 2. FUNÇÃO PARA CÁLCULO DAS MÉTRICAS DE PRESENÇA\n",
    "# (Versão já corrigida da etapa anterior)\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_presence_metrics(file_x, file_y):\n",
    "    \"\"\"\n",
    "    Calcula as métricas de concordância de presença para um único ponto no tempo.\n",
    "    \"\"\"\n",
    "    with rasterio.open(file_x) as src_x, rasterio.open(file_y) as src_y:\n",
    "        array_x = src_x.read(1)\n",
    "        array_y = src_y.read(1)\n",
    "        valid_mask = (array_x != nodata_value) & (array_y != nodata_value)\n",
    "        presence_x = array_x[valid_mask]\n",
    "        presence_y = array_y[valid_mask]\n",
    "\n",
    "        hits = np.sum(np.minimum(presence_x, presence_y))\n",
    "        total_x = np.sum(presence_x)\n",
    "        total_y = np.sum(presence_y)\n",
    "\n",
    "        # --- CORREÇÃO DE OVERFLOW ---\n",
    "        # Converte os totais para um tipo de inteiro com sinal (int64) antes da subtração\n",
    "        # para evitar o erro de 'overflow'.\n",
    "        hits = hits.astype(np.int64)\n",
    "        total_x = total_x.astype(np.int64)\n",
    "        total_y = total_y.astype(np.int64)\n",
    "        # --- FIM DA CORREÇÃO ---\n",
    "\n",
    "        space_difference = np.minimum(total_x, total_y) - hits\n",
    "        misses = np.maximum(0, total_x - total_y)\n",
    "        false_alarms = np.maximum(0, total_y - total_x)\n",
    "\n",
    "        return {\n",
    "            \"Hit\": hits, \"Miss\": misses, \"False Alarm\": false_alarms,\n",
    "            \"Space Difference\": space_difference, \"Total X\": total_x, \"Total Y\": total_y\n",
    "        }\n",
    "\n",
    "# =============================================================================\n",
    "# 3. PROCESSAMENTO DA SÉRIE TEMPORAL\n",
    "# =============================================================================\n",
    "\n",
    "results_by_time = {}\n",
    "print(\"Iniciando o processamento da série temporal...\")\n",
    "for year in time_points:\n",
    "    # Monta o nome do arquivo com base no padrão padronizado: {classe}{ano}.tif\n",
    "    file_name = f\"{class_name}{year}.tif\"\n",
    "    file_x = os.path.join(path_series_x, file_name)\n",
    "    file_y = os.path.join(path_series_y, file_name)\n",
    "\n",
    "    # Verifica se ambos os arquivos existem antes de processar\n",
    "    if os.path.exists(file_x) and os.path.exists(file_y):\n",
    "        print(f\"Processando: {file_name}...\")\n",
    "        results_by_time[year] = calculate_presence_metrics(file_x, file_y)\n",
    "    else:\n",
    "        print(f\"Aviso: Arquivo '{file_name}' não encontrado em ambas as pastas. Pulando.\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. CÁLCULO DOS TOTAIS (SUM) - LÓGICA FINAL CORRIGIDA\n",
    "# =============================================================================\n",
    "\n",
    "sum_results = {\n",
    "    \"Hit\": 0, \"Space Difference\": 0, \"Total X\": 0, \"Total Y\": 0\n",
    "}\n",
    "\n",
    "# Soma os componentes de Hit, Space Difference e Totais de todos os anos\n",
    "for year in results_by_time:\n",
    "    sum_results[\"Hit\"] += results_by_time[year][\"Hit\"]\n",
    "    sum_results[\"Space Difference\"] += results_by_time[year][\"Space Difference\"]\n",
    "    sum_results[\"Total X\"] += results_by_time[year][\"Total X\"]\n",
    "    sum_results[\"Total Y\"] += results_by_time[year][\"Total Y\"]\n",
    "\n",
    "# Calcula Time Difference (Equação 10)\n",
    "sum_results[\"Time Difference\"] = (\n",
    "    np.minimum(sum_results[\"Total X\"], sum_results[\"Total Y\"])\n",
    "    - sum_results[\"Hit\"]\n",
    "    - sum_results[\"Space Difference\"]\n",
    ")\n",
    "\n",
    "# --- CORREÇÃO FINAL APLICADA AQUI ---\n",
    "# Calcula Miss e False Alarm para a barra \"Sum\" com base nos totais gerais.\n",
    "# Um desses valores será sempre zero. (Equações 11 e 12)\n",
    "\n",
    "sum_results[\"Miss\"] = np.maximum(0, sum_results[\"Total X\"] - sum_results[\"Total Y\"])\n",
    "sum_results[\"False Alarm\"] = np.maximum(0, sum_results[\"Total Y\"] - sum_results[\"Total X\"])\n",
    "# --- FIM DA CORREÇÃO FINAL ---\n",
    "\n",
    "# =============================================================================\n",
    "# 5. GERAÇÃO DO GRÁFICO\n",
    "# =============================================================================\n",
    "print(\"\\nGerando o gráfico...\")\n",
    "\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "\n",
    "labels = [str(tp) for tp in time_points] + [\"Sum\"]\n",
    "\n",
    "# Dados para as barras e linhas\n",
    "hits = [results_by_time.get(tp, {}).get(\"Hit\", 0) for tp in time_points] + [sum_results[\"Hit\"]]\n",
    "space_diff = [results_by_time.get(tp, {}).get(\"Space Difference\", 0) for tp in time_points] + [sum_results[\"Space Difference\"]]\n",
    "time_diff = [0] * len(time_points) + [sum_results[\"Time Difference\"]]\n",
    "misses = [results_by_time.get(tp, {}).get(\"Miss\", 0) for tp in time_points] + [sum_results[\"Miss\"]]\n",
    "false_alarms = [results_by_time.get(tp, {}).get(\"False Alarm\", 0) for tp in time_points] + [sum_results[\"False Alarm\"]]\n",
    "\n",
    "reference_line = [results_by_time.get(tp, {}).get(\"Total X\", 0) for tp in time_points]\n",
    "comparison_line = [results_by_time.get(tp, {}).get(\"Total Y\", 0) for tp in time_points]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# --- Plotagem dos elementos ---\n",
    "bottom = np.zeros(len(labels))\n",
    "ax.bar(labels, hits, label='Hit', color='black', bottom=bottom); bottom += np.array(hits)\n",
    "ax.bar(labels, space_diff, label='Space Difference', color='grey', bottom=bottom); bottom += np.array(space_diff)\n",
    "ax.bar(labels, time_diff, label='Time Difference', color='lightgray', bottom=bottom); bottom += np.array(time_diff)\n",
    "ax.bar(labels, misses, label='Miss', color='white', edgecolor='black', hatch='\\\\\\\\\\\\', bottom=bottom); bottom += np.array(misses)\n",
    "ax.bar(labels, false_alarms, label='False Alarm', color='white', edgecolor='black', hatch='///', bottom=bottom)\n",
    "\n",
    "ax.plot(labels[:-1], reference_line, 's-g', label='Reference', linewidth=2, markersize=8)\n",
    "ax.plot(labels[:-1], comparison_line, 'd--y', label='Comparison', linewidth=2, markersize=8)\n",
    "\n",
    "\n",
    "# --- LÓGICA PARA ORDENAR A LEGENDA ---\n",
    "# 1. Pega todos os handles e labels que foram plotados\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# 2. Define a ordem desejada para os labels (com a correção)\n",
    "order = [\"Reference\", \"Comparison\", \"Miss\", \"False Alarm\", \"Time Difference\", \"Space Difference\", \"Hit\"]\n",
    "\n",
    "# 3. Cria um dicionário para mapear labels aos seus handles\n",
    "legend_dict = dict(zip(labels, handles))\n",
    "\n",
    "# 4. Reorganiza os handles e labels de acordo com a lista 'order'\n",
    "ordered_handles = [legend_dict[label] for label in order]\n",
    "ordered_labels = order\n",
    "\n",
    "# 5. Cria a legenda com os itens já ordenados\n",
    "ax.legend(ordered_handles, ordered_labels, loc='center left', bbox_to_anchor=(1, 0.5), frameon=False)\n",
    "# --- FIM DA LÓGICA DE ORDENAÇÃO ---\n",
    "\n",
    "ax.set_title('Time Points and Sum', fontsize=14)\n",
    "ax.set_xlabel('Time Point', fontsize=12)\n",
    "ax.set_ylabel('Presence (Number of pixels)', fontsize=12)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "\n",
    "output_filename = f'presence_agreement_{class_name}_final_ordered.png'\n",
    "plt.savefig(output_filename, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nProcessamento concluído. Gráfico salvo como: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d2d6be",
   "metadata": {},
   "source": [
    "## Gross Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc10c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NOVA CÉLULA: Ganhos e Perdas Brutos por Intervalo de Tempo (Versão Final com Extent)\n",
    "# =============================================================================\n",
    "print(\"✅ Iniciando a Célula de Cálculo de Ganhos e Perdas.\")\n",
    "\n",
    "# Dicionário para armazenar os arrays de raster e evitar releituras nesta célula\n",
    "raster_arrays = {}\n",
    "\n",
    "def get_raster_array(year):\n",
    "    \"\"\"\n",
    "    Lê um par de arquivos raster (x e y) para um dado ano ou o retorna \n",
    "    do cache se já tiver sido lido anteriormente nesta célula.\n",
    "    \"\"\"\n",
    "    if year in raster_arrays:\n",
    "        return raster_arrays[year]\n",
    "    \n",
    "    file_name = f\"{class_name}{year}.tif\"\n",
    "    path_x = os.path.join(path_series_x, file_name)\n",
    "    path_y = os.path.join(path_series_y, file_name)\n",
    "\n",
    "    if not os.path.exists(path_x) or not os.path.exists(path_y):\n",
    "        print(f\"Aviso: Arquivo '{file_name}' não encontrado para o ano {year}.\")\n",
    "        return None, None\n",
    "\n",
    "    print(f\"Lendo do disco: {file_name}...\")\n",
    "    with rasterio.open(path_x) as src_x, rasterio.open(path_y) as src_y:\n",
    "        array_x = src_x.read(1)\n",
    "        array_y = src_y.read(1)\n",
    "        # Armazena os arrays no cache para uso futuro nesta célula\n",
    "        raster_arrays[year] = (array_x, array_y)\n",
    "        return array_x, array_y\n",
    "\n",
    "# =============================================================================\n",
    "# 1. FUNÇÕES DE CÁLCULO DE MÉTRICAS\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_change_metrics(year_t, year_t_minus_1):\n",
    "    array_x_t, array_y_t = get_raster_array(year_t)\n",
    "    array_x_t_minus_1, array_y_t_minus_1 = get_raster_array(year_t_minus_1)\n",
    "    if array_x_t is None or array_x_t_minus_1 is None: return None\n",
    "    valid_mask = (array_x_t != nodata_value) & (array_y_t != nodata_value) & \\\n",
    "                 (array_x_t_minus_1 != nodata_value) & (array_y_t_minus_1 != nodata_value)\n",
    "    px_t, py_t = array_x_t[valid_mask].astype(np.int64), array_y_t[valid_mask].astype(np.int64)\n",
    "    px_t_minus_1, py_t_minus_1 = array_x_t_minus_1[valid_mask].astype(np.int64), array_y_t_minus_1[valid_mask].astype(np.int64)\n",
    "    gain_x, gain_y = np.maximum(0, px_t - px_t_minus_1), np.maximum(0, py_t - py_t_minus_1)\n",
    "    gain_total_x, gain_total_y = np.sum(gain_x), np.sum(gain_y)\n",
    "    gain_hit = np.sum(np.minimum(gain_x, gain_y))\n",
    "    gain_space_diff = np.minimum(gain_total_x, gain_total_y) - gain_hit\n",
    "    gain_miss = np.maximum(0, gain_total_x - gain_total_y)\n",
    "    gain_false_alarm = np.maximum(0, gain_total_y - gain_total_x)\n",
    "    loss_x, loss_y = np.minimum(0, px_t - px_t_minus_1), np.minimum(0, py_t - py_t_minus_1)\n",
    "    loss_total_x, loss_total_y = np.sum(loss_x), np.sum(loss_y)\n",
    "    loss_hit = np.sum(np.maximum(loss_x, loss_y))\n",
    "    loss_space_diff = np.maximum(loss_total_x, loss_total_y) - loss_hit\n",
    "    loss_miss = np.minimum(0, loss_total_x - loss_total_y)\n",
    "    loss_false_alarm = np.minimum(0, loss_total_y - loss_total_x)\n",
    "    return {\"Gain Hit\": gain_hit, \"Gain Miss\": gain_miss, \"Gain False Alarm\": gain_false_alarm, \"Gain Space Difference\": gain_space_diff,\n",
    "            \"Loss Hit\": loss_hit, \"Loss Miss\": loss_miss, \"Loss False Alarm\": loss_false_alarm, \"Loss Space Difference\": loss_space_diff,\n",
    "            \"Gain Total X\": gain_total_x, \"Gain Total Y\": gain_total_y, \"Loss Total X\": loss_total_x, \"Loss Total Y\": loss_total_y}\n",
    "\n",
    "def calculate_extent_metrics(time_points_list):\n",
    "    \"\"\"\n",
    "    Calcula as métricas de ganho e perda para a extensão temporal total.\n",
    "    \"\"\"\n",
    "    start_year, end_year = time_points_list[0], time_points_list[-1]\n",
    "    array_x_start, array_y_start = get_raster_array(start_year)\n",
    "    array_x_end, array_y_end = get_raster_array(end_year)\n",
    "    if array_x_start is None or array_x_end is None: return None\n",
    "    valid_mask = (array_x_start != nodata_value) & (array_y_start != nodata_value) & \\\n",
    "                 (array_x_end != nodata_value) & (array_y_end != nodata_value)\n",
    "    px_start, py_start = array_x_start[valid_mask].astype(np.int64), array_y_start[valid_mask].astype(np.int64)\n",
    "    px_end, py_end = array_x_end[valid_mask].astype(np.int64), array_y_end[valid_mask].astype(np.int64)\n",
    "    gain_x, gain_y = np.maximum(0, px_end - px_start), np.maximum(0, py_end - py_start)\n",
    "    gain_total_x, gain_total_y = np.sum(gain_x), np.sum(gain_y)\n",
    "    gain_hit = np.sum(np.minimum(gain_x, gain_y))\n",
    "    gain_space_diff = np.minimum(gain_total_x, gain_total_y) - gain_hit\n",
    "    gain_miss = np.maximum(0, gain_total_x - gain_total_y)\n",
    "    gain_false_alarm = np.maximum(0, gain_total_y - gain_total_x)\n",
    "    loss_x, loss_y = np.minimum(0, px_end - px_start), np.minimum(0, py_end - py_start)\n",
    "    loss_total_x, loss_total_y = np.sum(loss_x), np.sum(loss_y)\n",
    "    loss_hit = np.sum(np.maximum(loss_x, loss_y))\n",
    "    loss_space_diff = np.maximum(loss_total_x, loss_total_y) - loss_hit\n",
    "    loss_miss = np.minimum(0, loss_total_x - loss_total_y)\n",
    "    loss_false_alarm = np.minimum(0, loss_total_y - loss_total_x)\n",
    "    return {\"Gain Hit\": gain_hit, \"Gain Miss\": gain_miss, \"Gain False Alarm\": gain_false_alarm, \"Gain Space Difference\": gain_space_diff,\n",
    "            \"Loss Hit\": loss_hit, \"Loss Miss\": loss_miss, \"Loss False Alarm\": loss_false_alarm, \"Loss Space Difference\": loss_space_diff}\n",
    "\n",
    "# =============================================================================\n",
    "# 2. PROCESSAMENTO DOS INTERVALOS E DO EXTENT\n",
    "# =============================================================================\n",
    "change_results_by_interval = {}\n",
    "time_intervals = []\n",
    "print(\"Calculando métricas de mudança para cada intervalo...\")\n",
    "for i in range(1, len(time_points)):\n",
    "    year_t, year_t_minus_1 = time_points[i], time_points[i-1]\n",
    "    interval_label = f\"{year_t_minus_1}-{year_t}\"\n",
    "    time_intervals.append(interval_label)\n",
    "    print(f\"Processando intervalo: {interval_label}...\")\n",
    "    change_results_by_interval[interval_label] = calculate_change_metrics(year_t, year_t_minus_1)\n",
    "\n",
    "print(\"Calculando métricas para a Extensão Temporal...\")\n",
    "extent_results = calculate_extent_metrics(time_points)\n",
    "\n",
    "# =============================================================================\n",
    "# 3. CÁLCULO DOS TOTAIS (SUM) PARA MUDANÇA\n",
    "# =============================================================================\n",
    "sum_change_results = { \"Gain Hit\": 0, \"Gain Space Difference\": 0, \"Gain Total X\": 0, \"Gain Total Y\": 0, \"Gain Time Difference\": 0, \"Loss Hit\": 0, \"Loss Space Difference\": 0, \"Loss Total X\": 0, \"Loss Total Y\": 0, \"Loss Time Difference\": 0, }\n",
    "for interval in time_intervals:\n",
    "    results = change_results_by_interval[interval]\n",
    "    if results:\n",
    "        for key in [\"Gain Hit\", \"Gain Space Difference\", \"Gain Total X\", \"Gain Total Y\", \"Loss Hit\", \"Loss Space Difference\", \"Loss Total X\", \"Loss Total Y\"]:\n",
    "            sum_change_results[key] += results[key]\n",
    "sum_change_results[\"Gain Time Difference\"] = np.minimum(sum_change_results[\"Gain Total X\"], sum_change_results[\"Gain Total Y\"]) - sum_change_results[\"Gain Hit\"] - sum_change_results[\"Gain Space Difference\"]\n",
    "sum_change_results[\"Gain Miss\"] = np.maximum(0, sum_change_results[\"Gain Total X\"] - sum_change_results[\"Gain Total Y\"])\n",
    "sum_change_results[\"Gain False Alarm\"] = np.maximum(0, sum_change_results[\"Gain Total Y\"] - sum_change_results[\"Gain Total X\"])\n",
    "sum_change_results[\"Loss Time Difference\"] = np.maximum(sum_change_results[\"Loss Total X\"], sum_change_results[\"Loss Total Y\"]) - sum_change_results[\"Loss Hit\"] - sum_change_results[\"Loss Space Difference\"]\n",
    "sum_change_results[\"Loss Miss\"] = np.minimum(0, sum_change_results[\"Loss Total X\"] - sum_change_results[\"Loss Total Y\"])\n",
    "sum_change_results[\"Loss False Alarm\"] = np.minimum(0, sum_change_results[\"Loss Total Y\"] - sum_change_results[\"Loss Total X\"])\n",
    "\n",
    "# Importa a biblioteca de patches do Matplotlib, necessária para criar a legenda customizada\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# =============================================================================\n",
    "# 4. GERAÇÃO DO GRÁFICO DE GANHOS E PERDAS (LEGENDA CORRIGIDA)\n",
    "# =============================================================================\n",
    "print(\"\\nGerando o gráfico de Ganhos e Perdas...\")\n",
    "\n",
    "labels = time_intervals + [\"Sum\", \"Extent\"]\n",
    "\n",
    "gain_colors = {\n",
    "    'Hit': '#0070C0',\n",
    "    'Space Difference': '#00B0F0',\n",
    "    'Time Difference': '#BDD7EE',\n",
    "    'Miss': 'white',\n",
    "    'False Alarm': 'white'\n",
    "}\n",
    "loss_colors = {\n",
    "    'Hit': '#C00000',\n",
    "    'Space Difference': '#FF0000',\n",
    "    'Time Difference': '#FF9696',\n",
    "    'Miss': 'white',\n",
    "    'False Alarm': 'white'\n",
    "}\n",
    "\n",
    "gain_hatch_color = '#0070C0'\n",
    "loss_hatch_color = '#FF0000'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# --- Plotagem dos Ganhos (Lógica inalterada) ---\n",
    "bottom_gain = np.zeros(len(labels))\n",
    "for comp in [\"Hit\", \"Space Difference\", \"Time Difference\", \"Miss\", \"False Alarm\"]:\n",
    "    data = [change_results_by_interval.get(interval, {}).get(f\"Gain {comp}\", 0) for interval in time_intervals]\n",
    "    data.append(sum_change_results.get(f\"Gain {comp}\", 0))\n",
    "    data.append(extent_results.get(f\"Gain {comp}\", 0))\n",
    "    if comp == \"Time Difference\": data[-1] = 0\n",
    "    if comp in [\"Miss\", \"False Alarm\"]:\n",
    "        hatch = '///' if comp == 'False Alarm' else '\\\\\\\\\\\\'\n",
    "        ax.bar(labels, data, label=f'Gain {comp}', color='white', bottom=bottom_gain, edgecolor='black')\n",
    "        ax.bar(labels, data, color='none', bottom=bottom_gain, edgecolor=gain_hatch_color, hatch=hatch)\n",
    "    else:\n",
    "        ax.bar(labels, data, label=f'Gain {comp}', color=gain_colors[comp], bottom=bottom_gain, edgecolor='none')\n",
    "    bottom_gain += np.array(data)\n",
    "\n",
    "# --- Plotagem das Perdas (Lógica inalterada) ---\n",
    "bottom_loss = np.zeros(len(labels))\n",
    "for comp in [\"Hit\", \"Space Difference\", \"Time Difference\", \"Miss\", \"False Alarm\"]:\n",
    "    data = [change_results_by_interval.get(interval, {}).get(f\"Loss {comp}\", 0) for interval in time_intervals]\n",
    "    data.append(sum_change_results.get(f\"Loss {comp}\", 0))\n",
    "    data.append(extent_results.get(f\"Loss {comp}\", 0))\n",
    "    if comp == \"Time Difference\": data[-1] = 0\n",
    "    if comp in [\"Miss\", \"False Alarm\"]:\n",
    "        hatch = '///' if comp == 'False Alarm' else '\\\\\\\\\\\\'\n",
    "        ax.bar(labels, data, label=f'Loss {comp}', color='white', bottom=bottom_loss, edgecolor='black')\n",
    "        ax.bar(labels, data, color='none', bottom=bottom_loss, edgecolor=loss_hatch_color, hatch=hatch)\n",
    "    else:\n",
    "        ax.bar(labels, data, label=f'Loss {comp}', color=loss_colors[comp], bottom=bottom_loss, edgecolor='none')\n",
    "    bottom_loss += np.array(data)\n",
    "\n",
    "# --- Configurações Finais do Gráfico ---\n",
    "ax.axhline(0, color='black', linewidth=0.8)\n",
    "ax.set_title('Gross Loss and Gain During Time Intervals', fontsize=14)\n",
    "ax.set_xlabel('Time Interval', fontsize=12)\n",
    "ax.set_ylabel('Gross Loss and Gross Gain', fontsize=12)\n",
    "ax.set_ylim(-6, 6)\n",
    "\n",
    "# --- LÓGICA PARA ORDENAR A LEGENDA (COM CORREÇÃO DOS HANDLES) ---\n",
    "handles, labels_list = ax.get_legend_handles_labels()\n",
    "legend_dict = dict(zip(labels_list, handles))\n",
    "\n",
    "# --- CRIAÇÃO DOS HANDLES PERSONALIZADOS PARA A LEGENDA ---\n",
    "# Para cada item hachurado, criamos uma legenda que é uma tupla de dois patches:\n",
    "# a base branca/borda preta + a hachura colorida/fundo transparente.\n",
    "legend_dict['Gain Miss'] = (\n",
    "    mpatches.Patch(facecolor='white', edgecolor='black'),\n",
    "    mpatches.Patch(facecolor='none', edgecolor=gain_hatch_color, hatch='\\\\\\\\\\\\')\n",
    ")\n",
    "legend_dict['Gain False Alarm'] = (\n",
    "    mpatches.Patch(facecolor='white', edgecolor='black'),\n",
    "    mpatches.Patch(facecolor='none', edgecolor=gain_hatch_color, hatch='///')\n",
    ")\n",
    "legend_dict['Loss Miss'] = (\n",
    "    mpatches.Patch(facecolor='white', edgecolor='black'),\n",
    "    mpatches.Patch(facecolor='none', edgecolor=loss_hatch_color, hatch='\\\\\\\\\\\\')\n",
    ")\n",
    "legend_dict['Loss False Alarm'] = (\n",
    "    mpatches.Patch(facecolor='white', edgecolor='black'),\n",
    "    mpatches.Patch(facecolor='none', edgecolor=loss_hatch_color, hatch='///')\n",
    ")\n",
    "\n",
    "order = [\n",
    "    'Gain Miss', 'Gain False Alarm', 'Gain Time Difference', 'Gain Space Difference', 'Gain Hit',\n",
    "    'Loss Miss', 'Loss False Alarm', 'Loss Time Difference', 'Loss Space Difference', 'Loss Hit'\n",
    "]\n",
    "ordered_handles = [legend_dict[label] for label in order]\n",
    "ordered_labels = order\n",
    "\n",
    "ax.legend(\n",
    "    handles=ordered_handles,\n",
    "    labels=ordered_labels,\n",
    "    loc='center left',\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "output_filename = f'change_agreement_{class_name}.png'\n",
    "plt.savefig(\n",
    "    output_filename,\n",
    "    dpi=300\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nProcessamento concluído. Gráfico salvo como: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e74aeae",
   "metadata": {},
   "source": [
    "## Net Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f7d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NOVA CÉLULA: Gráfico de Mudança Líquida (Net Change) - Versão Final\n",
    "# =============================================================================\n",
    "print(\"✅ Iniciando a Célula de Gráfico de Mudança Líquida (Baseado nas Equações).\")\n",
    "\n",
    "# Importa a biblioteca de patches, caso a célula seja executada de forma independente\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# =============================================================================\n",
    "# 1. FUNÇÃO PARA CÁLCULO DOS COMPONENTES DE MUDANÇA LÍQUIDA\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_net_change_components(gross_results):\n",
    "    \"\"\"\n",
    "    Calcula os componentes de Net Change a partir dos resultados de Gross Change,\n",
    "    seguindo as equações 41-48 do artigo.\n",
    "    \"\"\"\n",
    "    if not gross_results:\n",
    "        return None\n",
    "\n",
    "    # --- Passo 1: Calcular Quantity Gain e Quantity Loss (Eqs. 41-44) ---\n",
    "    Ght, Gut, Gmt, Gft = gross_results[\"Gain Hit\"], gross_results[\"Gain Space Difference\"], gross_results[\"Gain Miss\"], gross_results[\"Gain False Alarm\"]\n",
    "    Lht, Lut, Lmt, Lft = gross_results[\"Loss Hit\"], gross_results[\"Loss Space Difference\"], gross_results[\"Loss Miss\"], gross_results[\"Loss False Alarm\"]\n",
    "\n",
    "    QGxt = np.maximum(0, Ght + Gut + Gmt + Lht + Lut + Lmt)\n",
    "    QGyt = np.maximum(0, Ght + Gut + Gft + Lht + Lut + Lft)\n",
    "    QLxt = np.minimum(0, Ght + Gut + Gmt + Lht + Lut + Lmt)\n",
    "    QLyt = np.minimum(0, Ght + Gut + Gft + Lht + Lut + Lft)\n",
    "\n",
    "    # --- Passo 2: Calcular os componentes de Net Change ---\n",
    "    net_gain_hit = np.minimum(QGxt, QGyt)\n",
    "    net_gain_miss = np.maximum(0, QGxt - QGyt)\n",
    "    net_gain_false_alarm = np.maximum(0, QGyt - QGxt)\n",
    "    net_loss_hit = np.maximum(QLxt, QLyt)\n",
    "    net_loss_miss = np.minimum(0, QLxt - QLyt)\n",
    "    net_loss_false_alarm = np.minimum(0, QLyt - QLxt)\n",
    "    \n",
    "    return {\n",
    "        \"Gain Hit\": net_gain_hit, \"Gain Miss\": net_gain_miss, \"Gain False Alarm\": net_gain_false_alarm,\n",
    "        \"Loss Hit\": net_loss_hit, \"Loss Miss\": net_loss_miss, \"Loss False Alarm\": net_loss_false_alarm,\n",
    "        \"QG_Total_X\": QGxt, \"QG_Total_Y\": QGyt, \"QL_Total_X\": QLxt, \"QL_Total_Y\": QLyt\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# 2. PROCESSAMENTO PARA OBTER OS COMPONENTES DE NET CHANGE\n",
    "# =============================================================================\n",
    "net_change_by_interval = {}\n",
    "print(\"Calculando os componentes de Mudança Líquida para cada intervalo...\")\n",
    "for interval_label, gross_results in change_results_by_interval.items():\n",
    "    net_change_by_interval[interval_label] = calculate_net_change_components(gross_results)\n",
    "\n",
    "print(\"Calculando os componentes de Mudança Líquida para a Extensão...\")\n",
    "net_extent_results = calculate_net_change_components(extent_results)\n",
    "\n",
    "# =============================================================================\n",
    "# 3. CÁLCULO DOS TOTAIS (SUM) PARA NET CHANGE - LÓGICA CORRIGIDA\n",
    "# =============================================================================\n",
    "print(\"Calculando os componentes de Mudança Líquida para a Soma...\")\n",
    "sum_net_results = { \n",
    "    \"QG_Total_X\": 0, \"QG_Total_Y\": 0, \"QL_Total_X\": 0, \"QL_Total_Y\": 0,\n",
    "    \"Gain Hit\": 0, \"Loss Hit\": 0 # Inicializa os hits da soma\n",
    "}\n",
    "# Primeiro, acumula os totais de QG, QL e os HITS de cada intervalo\n",
    "for interval, results in net_change_by_interval.items():\n",
    "    if results:\n",
    "        sum_net_results[\"QG_Total_X\"] += results[\"QG_Total_X\"]\n",
    "        sum_net_results[\"QG_Total_Y\"] += results[\"QG_Total_Y\"]\n",
    "        sum_net_results[\"QL_Total_X\"] += results[\"QL_Total_X\"]\n",
    "        sum_net_results[\"QL_Total_Y\"] += results[\"QL_Total_Y\"]\n",
    "        # Acumula os hits dos intervalos para obter o Hit da barra SUM\n",
    "        sum_net_results[\"Gain Hit\"] += results[\"Gain Hit\"]\n",
    "        sum_net_results[\"Loss Hit\"] += results[\"Loss Hit\"]\n",
    "\n",
    "# Agora, calcula os componentes finais para a barra SUM\n",
    "# Miss e False Alarm são calculados a partir dos totais de quantidade\n",
    "sum_net_results[\"Gain Miss\"] = np.maximum(0, sum_net_results[\"QG_Total_X\"] - sum_net_results[\"QG_Total_Y\"])\n",
    "sum_net_results[\"Gain False Alarm\"] = np.maximum(0, sum_net_results[\"QG_Total_Y\"] - sum_net_results[\"QG_Total_X\"])\n",
    "sum_net_results[\"Loss Miss\"] = np.minimum(0, sum_net_results[\"QL_Total_X\"] - sum_net_results[\"QL_Total_Y\"])\n",
    "sum_net_results[\"Loss False Alarm\"] = np.minimum(0, sum_net_results[\"QL_Total_Y\"] - sum_net_results[\"QL_Total_X\"])\n",
    "\n",
    "# Time Difference é o que sobra da concordância de quantidade depois de subtrair a soma dos hits\n",
    "sum_net_results[\"Gain Time Difference\"] = np.minimum(sum_net_results[\"QG_Total_X\"], sum_net_results[\"QG_Total_Y\"]) - sum_net_results[\"Gain Hit\"]\n",
    "sum_net_results[\"Loss Time Difference\"] = np.maximum(sum_net_results[\"QL_Total_X\"], sum_net_results[\"QL_Total_Y\"]) - sum_net_results[\"Loss Hit\"]\n",
    "\n",
    "# =============================================================================\n",
    "# 4. GERAÇÃO DO GRÁFICO DE MUDANÇA LÍQUIDA\n",
    "# =============================================================================\n",
    "print(\"\\nGerando o gráfico de Mudança Líquida...\")\n",
    "labels = time_intervals + [\"Sum\", \"Extent\"]\n",
    "gain_colors = {'Hit': '#0070C0', 'Time Difference': '#BDD7EE', 'Miss': 'white', 'False Alarm': 'white'}\n",
    "loss_colors = {'Hit': '#C00000', 'Time Difference': '#FF9696', 'Miss': 'white', 'False Alarm': 'white'}\n",
    "gain_hatch_color, loss_hatch_color = '#0070C0', '#FF0000'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# --- Plotagem dos Ganhos Líquidos ---\n",
    "bottom_gain = np.zeros(len(labels))\n",
    "for comp in [\"Hit\", \"Time Difference\", \"Miss\", \"False Alarm\"]:\n",
    "    data = [net_change_by_interval.get(interval, {}).get(f\"Gain {comp}\", 0) for interval in time_intervals]\n",
    "    data.append(sum_net_results.get(f\"Gain {comp}\", 0))\n",
    "    data.append(net_extent_results.get(f\"Gain {comp}\", 0) if comp != \"Time Difference\" else 0)\n",
    "    \n",
    "    hatch = '///' if comp == 'False Alarm' else '\\\\\\\\\\\\' if comp == 'Miss' else None\n",
    "    if hatch:\n",
    "        ax.bar(labels, data, label=f'Gain {comp}', color='white', bottom=bottom_gain, edgecolor='black')\n",
    "        ax.bar(labels, data, color='none', bottom=bottom_gain, edgecolor=gain_hatch_color, hatch=hatch)\n",
    "    else:\n",
    "        ax.bar(labels, data, label=f'Gain {comp}', color=gain_colors[comp], bottom=bottom_gain, edgecolor='none')\n",
    "    bottom_gain += np.array(data)\n",
    "\n",
    "# --- Plotagem das Perdas Líquidas ---\n",
    "bottom_loss = np.zeros(len(labels))\n",
    "for comp in [\"Hit\", \"Time Difference\", \"Miss\", \"False Alarm\"]:\n",
    "    data = [net_change_by_interval.get(interval, {}).get(f\"Loss {comp}\", 0) for interval in time_intervals]\n",
    "    data.append(sum_net_results.get(f\"Loss {comp}\", 0))\n",
    "    data.append(net_extent_results.get(f\"Loss {comp}\", 0) if comp != \"Time Difference\" else 0)\n",
    "    \n",
    "    hatch = '///' if comp == 'False Alarm' else '\\\\\\\\\\\\' if comp == 'Miss' else None\n",
    "    if hatch:\n",
    "        ax.bar(labels, data, label=f'Loss {comp}', color='white', bottom=bottom_loss, edgecolor='black')\n",
    "        ax.bar(labels, data, color='none', bottom=bottom_loss, edgecolor=loss_hatch_color, hatch=hatch)\n",
    "    else:\n",
    "        ax.bar(labels, data, label=f'Loss {comp}', color=loss_colors[comp], bottom=bottom_loss, edgecolor='none')\n",
    "    bottom_loss += np.array(data)\n",
    "\n",
    "# --- Configurações Finais ---\n",
    "ax.axhline(0, color='black', linewidth=0.8)\n",
    "ax.set_title('Quantity Loss and Gain During Time Intervlas', fontsize=14)\n",
    "ax.set_xlabel('Time Interval', fontsize=12)\n",
    "ax.set_ylabel('Net Loss and Net Gain', fontsize=12)\n",
    "ax.set_ylim(-6, 6)\n",
    "\n",
    "handles, labels_list = ax.get_legend_handles_labels()\n",
    "legend_dict = dict(zip(labels_list, handles))\n",
    "legend_dict['Gain Miss'] = (mpatches.Patch(facecolor='white', edgecolor='black'), mpatches.Patch(facecolor='none', edgecolor=gain_hatch_color, hatch='\\\\\\\\\\\\'))\n",
    "legend_dict['Gain False Alarm'] = (mpatches.Patch(facecolor='white', edgecolor='black'), mpatches.Patch(facecolor='none', edgecolor=gain_hatch_color, hatch='///'))\n",
    "legend_dict['Loss Miss'] = (mpatches.Patch(facecolor='white', edgecolor='black'), mpatches.Patch(facecolor='none', edgecolor=loss_hatch_color, hatch='\\\\\\\\\\\\'))\n",
    "legend_dict['Loss False Alarm'] = (mpatches.Patch(facecolor='white', edgecolor='black'), mpatches.Patch(facecolor='none', edgecolor=loss_hatch_color, hatch='///'))\n",
    "order = ['Gain Miss', 'Gain False Alarm', 'Gain Time Difference', 'Gain Hit', 'Loss Miss', 'Loss False Alarm', 'Loss Time Difference', 'Loss Hit']\n",
    "ordered_handles = [legend_dict.get(label) for label in order]\n",
    "ordered_labels = order\n",
    "\n",
    "ax.legend(handles=ordered_handles, labels=ordered_labels, loc='center left', bbox_to_anchor=(1, 0.5), frameon=False)\n",
    "output_filename = f'net_change_agreement_{class_name}.png'\n",
    "plt.savefig(output_filename, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nProcessamento concluído. Gráfico de Mudança Líquida salvo como: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39710f1c",
   "metadata": {},
   "source": [
    "# Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b7d18a",
   "metadata": {},
   "source": [
    "## Presence Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f154a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NOVA CÉLULA: Mapa de Concordância de Presença Acumulada (An) - Versão Final\n",
    "# =============================================================================\n",
    "print(\"Iniciando a Célula de Geração de Mapa de Concordância de Presença (An).\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. PREPARAÇÃO DO MAPA ACUMULADOR (Lógica inalterada)\n",
    "# =============================================================================\n",
    "\n",
    "first_year = time_points[0]\n",
    "first_file_name = f\"{class_name}{first_year}.tif\"\n",
    "path_to_first_file = os.path.join(path_series_x, first_file_name)\n",
    "\n",
    "try:\n",
    "    with rasterio.open(path_to_first_file) as src:\n",
    "        profile = src.profile\n",
    "        height, width = src.height, src.width\n",
    "        An_map = np.zeros((height, width), dtype=np.float32)\n",
    "        print(f\"Mapa acumulador 'An' inicializado com dimensões: {height}x{width}.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Não foi possível encontrar o arquivo de referência '{path_to_first_file}' para inicializar o mapa.\")\n",
    "    An_map = None\n",
    "\n",
    "# =============================================================================\n",
    "# 2. CÁLCULO E ACUMULAÇÃO DOS HITS DE PRESENÇA (Lógica inalterada)\n",
    "# =============================================================================\n",
    "\n",
    "if An_map is not None:\n",
    "    print(\"\\nIniciando o cálculo pixel a pixel para cada ponto no tempo...\")\n",
    "    final_nodata_mask = np.ones_like(An_map, dtype=bool)\n",
    "\n",
    "    for year in time_points:\n",
    "        file_name = f\"{class_name}{year}.tif\"\n",
    "        path_x = os.path.join(path_series_x, file_name)\n",
    "        path_y = os.path.join(path_series_y, file_name)\n",
    "\n",
    "        if os.path.exists(path_x) and os.path.exists(path_y):\n",
    "            print(f\"Processando: {file_name}...\")\n",
    "            with rasterio.open(path_x) as src_x, rasterio.open(path_y) as src_y:\n",
    "                array_x = src_x.read(1)\n",
    "                array_y = src_y.read(1)\n",
    "                \n",
    "                Phtn_map = np.minimum(array_x, array_y)\n",
    "                valid_mask = (array_x != nodata_value) & (array_y != nodata_value)\n",
    "                An_map[valid_mask] += Phtn_map[valid_mask]\n",
    "                \n",
    "                final_nodata_mask &= ~valid_mask\n",
    "        else:\n",
    "            print(f\"Aviso: Arquivos para o ano {year} não encontrados. Pulando.\")\n",
    "            \n",
    "    An_map[final_nodata_mask] = nodata_value\n",
    "\n",
    "# =============================================================================\n",
    "# 3. SALVAR E EXIBIR O MAPA FINAL (VERSÃO FINAL COM CORREÇÕES)\n",
    "# =============================================================================\n",
    "\n",
    "if An_map is not None:\n",
    "    profile.update(dtype=rasterio.float32, nodata=nodata_value)\n",
    "    output_filename_map = f'map_An_presence_agreement_{class_name}.tif'\n",
    "    print(f\"✅\\nSalvando o mapa final como: {output_filename_map}\")\n",
    "    with rasterio.open(output_filename_map, 'w', **profile) as dst:\n",
    "        dst.write(An_map, 1)\n",
    "\n",
    "    print(\"Gerando mapa...\")\n",
    "    \n",
    "    # --- Importações necessárias ---\n",
    "    from matplotlib.ticker import FuncFormatter\n",
    "    from pyproj import Transformer\n",
    "    from matplotlib_scalebar.scalebar import ScaleBar\n",
    "    from matplotlib_map_utils import north_arrow\n",
    "\n",
    "    # --- Preparação dos Dados e Metadados para o Mapa ---\n",
    "    with rasterio.open(output_filename_map) as src:\n",
    "        bounds = src.bounds\n",
    "        src_crs = src.crs\n",
    "        transform = src.transform\n",
    "        transformer = Transformer.from_crs(src_crs, \"EPSG:4326\", always_xy=True)\n",
    "        data = src.read(1)\n",
    "        masked_map = np.ma.masked_equal(data, nodata_value)\n",
    "    \n",
    "    # --- Lógica de Cores e Legenda Discreta (inalterada) ---\n",
    "    num_time_points = len(time_points)\n",
    "    viridis_colors = plt.get_cmap('viridis', num_time_points)\n",
    "    colors = ['gray'] + [viridis_colors(i / (num_time_points - 1)) for i in range(num_time_points)]\n",
    "    boundaries = list(range(num_time_points + 2))\n",
    "    cmap = ListedColormap(colors)\n",
    "    cmap.set_bad(color='white')\n",
    "    norm = BoundaryNorm(boundaries, cmap.N)\n",
    "\n",
    "    # --- Funções para Formatar os Ticks (inalterada) ---\n",
    "    def format_x_ticks(x, pos):\n",
    "        lon, _ = transformer.transform(x, bounds.bottom)\n",
    "        deg = int(abs(lon))\n",
    "        min_val = int((abs(lon) - deg) * 60)\n",
    "        sec = ((abs(lon) - deg) * 60 - min_val) * 60\n",
    "        return f\"{deg}° {min_val}' {sec:.2f}\\\"\" + (\"E\" if lon >= 0 else \"W\")\n",
    "\n",
    "    def format_y_ticks(y, pos):\n",
    "        _, lat = transformer.transform(bounds.left, y)\n",
    "        deg = int(abs(lat))\n",
    "        min_val = int((abs(lat) - deg) * 60)\n",
    "        sec = ((abs(lat) - deg) * 60 - min_val) * 60\n",
    "        return f\"{deg}° {min_val}' {sec:.2f}\\\"\" + (\"N\" if lat >= 0 else \"S\")\n",
    "\n",
    "    # --- Geração do Gráfico ---\n",
    "    fig, ax = plt.subplots(figsize=(14, 12))\n",
    "    mpl.rcParams['font.family'] = 'serif'\n",
    "    \n",
    "    im = ax.imshow(masked_map, cmap=cmap, norm=norm, extent=[bounds.left, bounds.right, bounds.bottom, bounds.top])\n",
    "    \n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(format_x_ticks))\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(format_y_ticks))\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(6))\n",
    "    ax.tick_params(axis='x', which='major', labelsize=10, pad=4)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=10, pad=4)\n",
    "    plt.setp(ax.get_yticklabels(), rotation=90, va='center')\n",
    "    \n",
    "    # Add north arrow\n",
    "    north_arrow(ax,\n",
    "                location=\"upper right\",\n",
    "                rotation={\"degrees\": 0})\n",
    "\n",
    "    # Add scale bar\n",
    "    def km_to_degrees(value, dimension):\n",
    "        approx_deg = value / 111  # Approximate conversion: 1° ≈ 111km\n",
    "        return f\"{approx_deg:.1f}°\"\n",
    "\n",
    "    scalebar = ScaleBar(\n",
    "        1/1000,\n",
    "        units='km',\n",
    "        length_fraction=0.4,\n",
    "        location='lower right',\n",
    "        scale_formatter=lambda value, _: f\"{int(value)} km\"\n",
    "    )\n",
    "    ax.add_artist(scalebar)\n",
    "\n",
    "    # --- Cria a Legenda Discreta ---\n",
    "    labels_legenda = [f'Stable Absence'] + [f'{i}' for i in range(1, num_time_points + 1)]\n",
    "    patches = [mpatches.Patch(color=colors[i], label=labels_legenda[i]) for i in range(len(labels_legenda))]\n",
    "    ax.legend(\n",
    "        handles=patches,\n",
    "        loc='center left',\n",
    "        bbox_to_anchor=(1.05, 0.5),\n",
    "        frameon=False,\n",
    "        fontsize=12\n",
    "    )\n",
    "    \n",
    "    # --- Ajustes Finais ---\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'Presence Agreement Map - {class_name.capitalize()}',\n",
    "                 fontsize=18,\n",
    "                 pad=20)\n",
    "    ax.set_xlabel('Longitude',\n",
    "                  fontsize=12)\n",
    "    ax.set_ylabel('Latitude',\n",
    "                  fontsize=12)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b45131",
   "metadata": {},
   "source": [
    "## Presence Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701b77a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =============================================================================\n",
    "# # NOVA CÉLULA: Mapa de Diferença de Presença Acumulada (Dn)\n",
    "# # =============================================================================\n",
    "# print(\"Iniciando a Célula de Geração de Mapa de Diferença de Presença (Dn).\")\n",
    "\n",
    "# # =============================================================================\n",
    "# # 1. CÁLCULO DO MAPA 'Dn' (Lógica inalterada)\n",
    "# # =============================================================================\n",
    "\n",
    "# try:\n",
    "#     with rasterio.open(path_to_first_file) as src:\n",
    "#         profile = src.profile\n",
    "#         height, width = src.height, src.width\n",
    "#         Dn_map = np.zeros((height, width), dtype=np.float32)\n",
    "#         print(f\"Mapa acumulador 'Dn' inicializado com dimensões: {height}x{width}.\")\n",
    "# except NameError:\n",
    "#     print(\"ERRO: A célula anterior (mapa An) precisa ser executada primeiro para definir 'path_to_first_file'.\")\n",
    "#     Dn_map = None\n",
    "\n",
    "# if Dn_map is not None:\n",
    "#     final_nodata_mask = np.ones_like(Dn_map, dtype=bool)\n",
    "#     for year in time_points:\n",
    "#         file_name = f\"{class_name}{year}.tif\"\n",
    "#         path_x = os.path.join(path_series_x, file_name)\n",
    "#         path_y = os.path.join(path_series_y, file_name)\n",
    "#         if os.path.exists(path_x) and os.path.exists(path_y):\n",
    "#             with rasterio.open(path_x) as src_x, rasterio.open(path_y) as src_y:\n",
    "#                 array_x = src_x.read(1).astype(np.int64)\n",
    "#                 array_y = src_y.read(1).astype(np.int64)\n",
    "#                 difference_map = array_y - array_x\n",
    "#                 valid_mask = (src_x.read(1) != nodata_value) & (src_y.read(1) != nodata_value)\n",
    "#                 Dn_map[valid_mask] += difference_map[valid_mask]\n",
    "#                 final_nodata_mask &= ~valid_mask\n",
    "#     Dn_map[final_nodata_mask] = nodata_value\n",
    "\n",
    "# # =============================================================================\n",
    "# # 2. SALVAR E EXIBIR O MAPA FINAL (COM AJUSTES FINAIS)\n",
    "# # =============================================================================\n",
    "\n",
    "# if Dn_map is not None:\n",
    "#     # --- Salva o arquivo GeoTIFF (lógica inalterada) ---\n",
    "#     output_filename_map_dn = f'map_Dn_presence_difference_{class_name}.tif'\n",
    "#     profile.update(dtype=rasterio.float32, nodata=nodata_value)\n",
    "#     print(f\"✅\\nSalvando o mapa final como: {output_filename_map_dn}\")\n",
    "#     with rasterio.open(output_filename_map_dn, 'w', **profile) as dst:\n",
    "#         dst.write(Dn_map, 1)\n",
    "\n",
    "#     print(\"Gerando mapa...\")\n",
    "    \n",
    "#     # --- Preparação dos Dados e Metadados para o Mapa ---\n",
    "#     with rasterio.open(output_filename_map_dn) as src:\n",
    "#         bounds = src.bounds\n",
    "#         src_crs = src.crs\n",
    "#         transform = src.transform\n",
    "#         transformer = Transformer.from_crs(src_crs,\n",
    "#                                            \"EPSG:4326\",\n",
    "#                                            always_xy=True)\n",
    "#         data = src.read(1)\n",
    "#         # Mascara apenas o NoData. O valor 0 será tratado pelo mapa de cores.\n",
    "#         masked_map = np.ma.masked_equal(data, nodata_value)\n",
    "\n",
    "#     # --- Lógica de Cores Personalizada (Vermelho -> Cinza -> Azul) ---\n",
    "#     # Cria uma paleta de cores personalizada que tem o cinza no centro (valor 0)\n",
    "#     colors = [\"#f72f47\",\n",
    "#               \"gray\",\n",
    "#               \"#87ee01\"]\n",
    "#     cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_div_cmap\", colors)\n",
    "    \n",
    "#     # Define a cor para NoData (valores mascarados) como branco\n",
    "#     cmap.set_bad(color='white')\n",
    "    \n",
    "#     # Encontra o valor absoluto máximo para centralizar a paleta de cores em 0\n",
    "#     max_abs_val = np.ma.max(np.abs(masked_map))\n",
    "#     norm = mcolors.Normalize(vmin=-max_abs_val, vmax=max_abs_val)\n",
    "\n",
    "#     # --- Funções para Formatar os Ticks (do template) ---\n",
    "#     def format_x_ticks(x, pos):\n",
    "#         lon, _ = transformer.transform(x, bounds.bottom)\n",
    "#         deg, min_val, sec = int(abs(lon)), int((abs(lon) - int(abs(lon))) * 60), (abs(lon) * 3600) % 60\n",
    "#         return f\"{deg}° {min_val}' {sec:.2f}\\\"\" + (\"E\" if lon >= 0 else \"W\")\n",
    "\n",
    "#     def format_y_ticks(y, pos):\n",
    "#         _, lat = transformer.transform(bounds.left, y)\n",
    "#         deg, min_val, sec = int(abs(lat)), int((abs(lat) - int(abs(lat))) * 60), (abs(lat) * 3600) % 60\n",
    "#         return f\"{deg}° {min_val}' {sec:.2f}\\\"\" + (\"N\" if lat >= 0 else \"S\")\n",
    "\n",
    "#     # --- Geração do Gráfico ---\n",
    "#     fig, ax = plt.subplots(figsize=(14, 12))\n",
    "#     mpl.rcParams['font.family'] = 'serif'\n",
    "    \n",
    "#     # Plota o mapa com a paleta de cores personalizada\n",
    "#     im = ax.imshow(masked_map, cmap=cmap, norm=norm, extent=[bounds.left, bounds.right, bounds.bottom, bounds.top])\n",
    "    \n",
    "#     ax.xaxis.set_major_formatter(FuncFormatter(format_x_ticks))\n",
    "#     ax.yaxis.set_major_formatter(FuncFormatter(format_y_ticks))\n",
    "#     ax.xaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "#     ax.yaxis.set_major_locator(plt.MaxNLocator(6))\n",
    "#     ax.tick_params(axis='x',\n",
    "#                    which='major',\n",
    "#                    labelsize=10, pad=4)\n",
    "#     ax.tick_params(axis='y',\n",
    "#                    which='major',\n",
    "#                    labelsize=10, pad=4)\n",
    "#     plt.setp(ax.get_yticklabels(),\n",
    "#              rotation=90,\n",
    "#              va='center')\n",
    "    \n",
    "#     north_arrow(ax,\n",
    "#                 location=\"upper right\",\n",
    "#                 rotation={\"degrees\": 0})\n",
    "    \n",
    "#     # Add scale bar\n",
    "#     def km_to_degrees(value, dimension):\n",
    "#         approx_deg = value / 111  # Approximate conversion: 1° ≈ 111km\n",
    "#         return f\"{approx_deg:.1f}°\"\n",
    "\n",
    "#     scalebar = ScaleBar(\n",
    "#         1/1000,\n",
    "#         units='km',\n",
    "#         length_fraction=0.4,\n",
    "#         location='lower right',\n",
    "#         scale_formatter=lambda value, _: f\"{int(value)} km\"\n",
    "#     )\n",
    "#     ax.add_artist(scalebar)\n",
    "\n",
    "#     # --- Legenda de Barra de Cores (Ajustada) ---\n",
    "#     # Usa o parâmetro 'shrink' para diminuir o tamanho e remove a chamada 'set_label'\n",
    "#     cbar = fig.colorbar(im,\n",
    "#                         ax=ax,\n",
    "#                         orientation='vertical',\n",
    "#                         fraction=0.046,\n",
    "#                         pad=0.04,\n",
    "#                         shrink=0.7)\n",
    "    \n",
    "#     # --- Ajustes Finais ---\n",
    "#     ax.set_aspect('equal')\n",
    "#     ax.set_title(f'Presence Disagreement Map - {class_name}',\n",
    "#                  fontsize=18,\n",
    "#                  pad=20)\n",
    "#     ax.set_xlabel('Longitude',\n",
    "#                   fontsize=12)\n",
    "#     ax.set_ylabel('Latitude',\n",
    "#                   fontsize=12)\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ddeae",
   "metadata": {},
   "source": [
    "## Change Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd47375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NOVA CÉLULA: Mapa de Predominância da Concordância de Mudança (Gain Hit vs Loss Hit)\n",
    "# =============================================================================\n",
    "print(\"✅ Iniciando a Célula de Geração do Mapa de Predominância da Concordância.\")\n",
    "\n",
    "# Adiciona a importação que estava faltando para esta célula\n",
    "# from rasterio.enums import Resampling\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CÁLCULO DOS MAPAS ACUMULADOS DE CONCORDÂNCIA\n",
    "# =============================================================================\n",
    "\n",
    "try:\n",
    "    with rasterio.open(path_to_first_file) as src:\n",
    "        profile = src.profile\n",
    "        height, width = src.height, src.width\n",
    "        # Inicializa dois mapas: um para a soma de Ghtn, outro para a soma de |Lhtn|\n",
    "        Ghtn_sum_map = np.zeros((height, width), dtype=np.float32)\n",
    "        Lhtn_sum_map = np.zeros((height, width), dtype=np.float32)\n",
    "        print(f\"Mapas acumuladores inicializados com dimensões: {height}x{width}.\")\n",
    "except NameError:\n",
    "    print(\"ERRO: A célula do primeiro mapa (An) precisa ser executada para definir as variáveis.\")\n",
    "    Ghtn_sum_map = None\n",
    "\n",
    "if Ghtn_sum_map is not None:\n",
    "    print(\"\\nCalculando a concordância de ganho e perda para cada intervalo...\")\n",
    "    final_nodata_mask = np.ones_like(Ghtn_sum_map, dtype=bool)\n",
    "\n",
    "    for i in range(1, len(time_points)):\n",
    "        year_t = time_points[i]\n",
    "        year_t_minus_1 = time_points[i-1]\n",
    "        print(f\"Processando intervalo: {year_t_minus_1}-{year_t}...\")\n",
    "        \n",
    "        array_x_t, array_y_t = get_raster_array(year_t)\n",
    "        array_x_t_minus_1, array_y_t_minus_1 = get_raster_array(year_t_minus_1)\n",
    "        if array_x_t is None: continue\n",
    "\n",
    "        valid_mask = (array_x_t != nodata_value) & (array_y_t != nodata_value) & \\\n",
    "                     (array_x_t_minus_1 != nodata_value) & (array_y_t_minus_1 != nodata_value)\n",
    "        \n",
    "        change_x = np.subtract(array_x_t, array_x_t_minus_1, dtype=np.int16)\n",
    "        change_y = np.subtract(array_y_t, array_y_t_minus_1, dtype=np.int16)\n",
    "        gain_x, gain_y = np.maximum(0, change_x), np.maximum(0, change_y)\n",
    "        loss_x, loss_y = np.minimum(0, change_x), np.minimum(0, change_y)\n",
    "        \n",
    "        Ghtn_map = np.minimum(gain_x, gain_y)\n",
    "        Lhtn_map = np.maximum(loss_x, loss_y)\n",
    "        \n",
    "        np.add(Ghtn_sum_map, Ghtn_map, out=Ghtn_sum_map, where=valid_mask)\n",
    "        # Subtraímos Lhtn (que é negativo) para somar sua magnitude\n",
    "        np.subtract(Lhtn_sum_map, Lhtn_map, out=Lhtn_sum_map, where=valid_mask)\n",
    "        \n",
    "        final_nodata_mask &= ~valid_mask\n",
    "            \n",
    "    # Define NoData nos pixels que nunca foram válidos\n",
    "    Ghtn_sum_map[final_nodata_mask] = nodata_value\n",
    "    Lhtn_sum_map[final_nodata_mask] = nodata_value\n",
    "\n",
    "# =============================================================================\n",
    "# 2. CLASSIFICAÇÃO DO MAPA DE DOMINÂNCIA\n",
    "# =============================================================================\n",
    "\n",
    "if Ghtn_sum_map is not None:\n",
    "    print(\"\\nClassificando os pixels por predominância...\")\n",
    "    # Inicializa o mapa de classes. 1 será a classe 'Sem Concordância'.\n",
    "    dominance_map = np.ones_like(Ghtn_sum_map, dtype=np.uint8)\n",
    "\n",
    "    # Define as classes com base na comparação dos totais acumulados\n",
    "    dominance_map = np.where(Ghtn_sum_map > Lhtn_sum_map, 2, dominance_map) # 2 = Ganho Predominante\n",
    "    dominance_map = np.where(Lhtn_sum_map > Ghtn_sum_map, 3, dominance_map) # 3 = Perda Predominante\n",
    "    dominance_map = np.where((Lhtn_sum_map == Ghtn_sum_map) & (Ghtn_sum_map > 0), 4, dominance_map) # 4 = Misto\n",
    "    \n",
    "    # Aplica a máscara de NoData ao mapa final\n",
    "    dominance_map[Ghtn_sum_map == nodata_value] = 255 # Usando 255 para NoData\n",
    "    \n",
    "# =============================================================================\n",
    "# 3. SALVAR E EXIBIR O MAPA FINAL (VERSÃO EM INGLÊS)\n",
    "# =============================================================================\n",
    "\n",
    "if 'dominance_map' in locals():\n",
    "    output_filename_map_dom = f'map_Predominance_change_agreement_{class_name}_EN.tif'\n",
    "    profile.update(dtype=rasterio.uint8, nodata=255)\n",
    "    print(f\"✅\\nSaving final map as: {output_filename_map_dom}\")\n",
    "    with rasterio.open(output_filename_map_dom, 'w', **profile) as dst:\n",
    "        dst.write(dominance_map, 1)\n",
    "\n",
    "    print(\"Generating map...\")\n",
    "    \n",
    "    scale_factor = 0.15\n",
    "\n",
    "    with rasterio.open(output_filename_map_dom) as src:\n",
    "        bounds, src_crs, transform = src.bounds, src.crs, src.transform\n",
    "        transformer = Transformer.from_crs(src_crs, \"EPSG:4326\", always_xy=True)\n",
    "        data = src.read(1, out_shape=(int(src.height * scale_factor), int(src.width * scale_factor)), resampling=Resampling.nearest)\n",
    "        masked_map = np.ma.masked_equal(data, 255)\n",
    "    \n",
    "    colors = {\n",
    "        1: 'gray',\n",
    "        2: '#0070C0',\n",
    "        3: '#C00000',\n",
    "        4: '#7030A0'\n",
    "    }\n",
    "    cmap = ListedColormap([colors[k] for k in sorted(colors.keys())])\n",
    "    boundaries = sorted(colors.keys()) + [5]\n",
    "    norm = BoundaryNorm(boundaries, cmap.N)\n",
    "    cmap.set_bad(color='white')\n",
    "\n",
    "    def format_x_ticks(x, pos):\n",
    "        lon, _ = transformer.transform(x, bounds.bottom)\n",
    "        deg, min_val, sec = int(abs(lon)), int((abs(lon) - int(abs(lon))) * 60), (abs(lon) * 3600) % 60\n",
    "        return f\"{deg}° {min_val}' {sec:.2f}\\\"\" + (\"E\" if lon >= 0 else \"W\")\n",
    "\n",
    "    def format_y_ticks(y, pos):\n",
    "        _, lat = transformer.transform(bounds.left, y)\n",
    "        deg, min_val, sec = int(abs(lat)), int((abs(lat) - int(abs(lat))) * 60), (abs(lat) * 3600) % 60\n",
    "        return f\"{deg}° {min_val}' {sec:.2f}\\\"\" + (\"N\" if lat >= 0 else \"S\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 12))\n",
    "    mpl.rcParams['font.family'] = 'serif'\n",
    "    \n",
    "    im = ax.imshow(masked_map, cmap=cmap, norm=norm, extent=[bounds.left, bounds.right, bounds.bottom, bounds.top])\n",
    "    \n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(format_x_ticks)); ax.yaxis.set_major_formatter(FuncFormatter(format_y_ticks))\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(3)); ax.yaxis.set_major_locator(plt.MaxNLocator(6))\n",
    "    ax.tick_params(axis='x', which='major', labelsize=10, pad=4); ax.tick_params(axis='y', which='major', labelsize=10, pad=4)\n",
    "    plt.setp(ax.get_yticklabels(), rotation=90, va='center')\n",
    "    \n",
    "    north_arrow(ax, location=\"upper right\", rotation={\"degrees\": 0})\n",
    "    scalebar = ScaleBar(1/1000, units='km', length_fraction=0.4, location='lower right', scale_formatter=lambda value, _: f\"{int(value)} km\")\n",
    "    ax.add_artist(scalebar)\n",
    "\n",
    "    labels_legenda = [\n",
    "        \"No Change Agreement\\n($\\Sigma$ Hits = 0)\",\n",
    "        \"Predominantly Gain\\n($\\Sigma$ Gain Hits > $\\Sigma$ |Loss Hits|)\",\n",
    "        \"Predominantly Loss\\n($\\Sigma$ |Loss Hits| > $\\Sigma$ Gain Hits)\",\n",
    "        \"Mixed Agreement\\n($\\Sigma$ Gain Hits = $\\Sigma$ |Loss Hits| > 0)\"\n",
    "    ]\n",
    "    patches = [mpatches.Patch(color=colors[i+1], label=labels_legenda[i]) for i in range(len(labels_legenda))]\n",
    "    ax.legend(\n",
    "        handles=patches,\n",
    "        title='Predominance of Change Agreement',\n",
    "        loc='center left',\n",
    "        bbox_to_anchor=(1.05, 0.5),\n",
    "        frameon=False,\n",
    "        fontsize=12\n",
    "    )\n",
    "    \n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'Predominance of Change Agreement - {class_name.capitalize()}', fontsize=18, pad=20)\n",
    "    ax.set_xlabel('Longitude', fontsize=12)\n",
    "    ax.set_ylabel('Latitude', fontsize=12)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15396655",
   "metadata": {},
   "source": [
    "## Change Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42efdb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =============================================================================\n",
    "# # NOVA CÉLULA: Mapa de Diferença de Mudança (En)\n",
    "# # =============================================================================\n",
    "# print(\"✅ Iniciando a Célula de Geração de Mapa de Diferença de Mudança (En).\")\n",
    "\n",
    "# # =============================================================================\n",
    "# # 1. CÁLCULO DO MAPA 'En'\n",
    "# # =============================================================================\n",
    "\n",
    "# try:\n",
    "#     with rasterio.open(path_to_first_file) as src:\n",
    "#         profile = src.profile\n",
    "#         height, width = src.height, src.width\n",
    "#         # Inicializa o mapa acumulador com zeros\n",
    "#         En_map = np.zeros((height, width), dtype=np.float32)\n",
    "#         print(f\"Mapa acumulador 'En' inicializado com dimensões: {height}x{width}.\")\n",
    "# except NameError:\n",
    "#     print(\"ERRO: A célula do primeiro mapa (An) precisa ser executada para definir as variáveis.\")\n",
    "#     En_map = None\n",
    "\n",
    "# if En_map is not None:\n",
    "#     print(\"\\nIniciando o cálculo da diferença de mudança para cada intervalo...\")\n",
    "#     final_nodata_mask = np.ones_like(En_map, dtype=bool)\n",
    "\n",
    "#     # Itera sobre os INTERVALOS de tempo\n",
    "#     for i in range(1, len(time_points)):\n",
    "#         year_t = time_points[i]\n",
    "#         year_t_minus_1 = time_points[i-1]\n",
    "        \n",
    "#         print(f\"Processando intervalo: {year_t_minus_1}-{year_t}...\")\n",
    "\n",
    "#         array_x_t, array_y_t = get_raster_array(year_t)\n",
    "#         array_x_t_minus_1, array_y_t_minus_1 = get_raster_array(year_t_minus_1)\n",
    "\n",
    "#         if array_x_t is None or array_x_t_minus_1 is None:\n",
    "#             continue\n",
    "\n",
    "#         valid_mask = (array_x_t != nodata_value) & (array_y_t != nodata_value) & \\\n",
    "#                      (array_x_t_minus_1 != nodata_value) & (array_y_t_minus_1 != nodata_value)\n",
    "        \n",
    "#         # Calcula a mudança em cada série (usando int16 para otimizar memória)\n",
    "#         change_x = np.subtract(array_x_t, array_x_t_minus_1, dtype=np.int16)\n",
    "#         change_y = np.subtract(array_y_t, array_y_t_minus_1, dtype=np.int16)\n",
    "        \n",
    "#         # Calcula a diferença entre as mudanças para o intervalo\n",
    "#         difference_of_changes = np.subtract(change_y, change_x, dtype=np.int16)\n",
    "        \n",
    "#         # Acumula o resultado de forma eficiente\n",
    "#         np.add(En_map, difference_of_changes, out=En_map, where=valid_mask)\n",
    "        \n",
    "#         final_nodata_mask &= ~valid_mask\n",
    "            \n",
    "#     En_map[final_nodata_mask] = nodata_value\n",
    "\n",
    "# # =============================================================================\n",
    "# # 2. SALVAR E EXIBIR O MAPA FINAL (USANDO SEU TEMPLATE)\n",
    "# # =============================================================================\n",
    "\n",
    "# if En_map is not None:\n",
    "#     output_filename_map_en = f'map_En_change_difference_{class_name}.tif'\n",
    "#     profile.update(dtype=rasterio.float32, nodata=nodata_value)\n",
    "#     print(f\"✅\\nSalvando o mapa final como: {output_filename_map_en}\")\n",
    "#     with rasterio.open(output_filename_map_en, 'w', **profile) as dst:\n",
    "#         dst.write(En_map, 1)\n",
    "\n",
    "#     print(\"Gerando mapa...\")\n",
    "    \n",
    "#     scale_factor = 0.15\n",
    "\n",
    "#     with rasterio.open(output_filename_map_en) as src:\n",
    "#         bounds, src_crs, transform = src.bounds, src.crs, src.transform\n",
    "#         transformer = Transformer.from_crs(src_crs, \"EPSG:4326\", always_xy=True)\n",
    "#         data = src.read(1, out_shape=(int(src.height * scale_factor), int(src.width * scale_factor)), resampling=Resampling.nearest)\n",
    "#         masked_map = np.ma.masked_equal(data, nodata_value)\n",
    "    \n",
    "#     # --- Lógica de Cores Personalizada (Roxo -> Cinza -> Verde) ---\n",
    "#     colors = [\"#8e44ad\", \"gray\", \"#27ae60\"]  # Roxo -> Cinza -> Verde\n",
    "#     cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_div_cmap\", colors)\n",
    "#     cmap.set_bad(color='white')\n",
    "#     max_abs_val = np.ma.max(np.abs(masked_map))\n",
    "#     norm = mcolors.Normalize(vmin=-max_abs_val, vmax=max_abs_val)\n",
    "\n",
    "#     # --- Funções para Formatar os Ticks (do template) ---\n",
    "#     def format_x_ticks(x, pos):\n",
    "#         lon, _ = transformer.transform(x, bounds.bottom)\n",
    "#         deg, min_val, sec = int(abs(lon)), int((abs(lon) - int(abs(lon))) * 60), (abs(lon) * 3600) % 60\n",
    "#         return f\"{deg}° {min_val}' {sec:.2f}\\\"\" + (\"E\" if lon >= 0 else \"W\")\n",
    "\n",
    "#     def format_y_ticks(y, pos):\n",
    "#         _, lat = transformer.transform(bounds.left, y)\n",
    "#         deg, min_val, sec = int(abs(lat)), int((abs(lat) - int(abs(lat))) * 60), (abs(lat) * 3600) % 60\n",
    "#         return f\"{deg}° {min_val}' {sec:.2f}\\\"\" + (\"N\" if lat >= 0 else \"S\")\n",
    "\n",
    "#     # --- Geração do Gráfico ---\n",
    "#     fig, ax = plt.subplots(figsize=(14, 12))\n",
    "#     mpl.rcParams['font.family'] = 'serif'\n",
    "    \n",
    "#     im = ax.imshow(masked_map, cmap=cmap, norm=norm, extent=[bounds.left, bounds.right, bounds.bottom, bounds.top])\n",
    "    \n",
    "#     ax.xaxis.set_major_formatter(FuncFormatter(format_x_ticks))\n",
    "#     ax.yaxis.set_major_formatter(FuncFormatter(format_y_ticks))\n",
    "#     ax.xaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "#     ax.yaxis.set_major_locator(plt.MaxNLocator(6))\n",
    "#     ax.tick_params(axis='x', which='major', labelsize=10, pad=4)\n",
    "#     ax.tick_params(axis='y', which='major', labelsize=10, pad=4)\n",
    "#     plt.setp(ax.get_yticklabels(), rotation=90, va='center')\n",
    "    \n",
    "#     north_arrow(ax, location=\"upper right\", rotation={\"degrees\": 0})\n",
    "    \n",
    "#     scalebar = ScaleBar(1/1000, units='km', length_fraction=0.4, location='lower right',\n",
    "#                         scale_formatter=lambda value, _: f\"{int(value)} km\")\n",
    "#     ax.add_artist(scalebar)\n",
    "\n",
    "#     # --- Legenda de Barra de Cores ---\n",
    "#     cbar = fig.colorbar(im, ax=ax, orientation='vertical', fraction=0.046, pad=0.04, shrink=0.7)\n",
    "    \n",
    "#     # --- Ajustes Finais ---\n",
    "#     ax.set_aspect('equal')\n",
    "#     ax.set_title(f'Mapa de Diferença de Mudança (En) - {class_name}', fontsize=18, pad=20)\n",
    "#     ax.set_xlabel('Longitude', fontsize=12)\n",
    "#     ax.set_ylabel('Latitude', fontsize=12)\n",
    "    \n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
